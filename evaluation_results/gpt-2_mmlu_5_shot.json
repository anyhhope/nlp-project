{"astronomy_test.csv": 0.24, "high_school_statistics_test.csv": 0.14285714285714285, "anatomy_test.csv": 0.18181818181818182, "world_religions_test.csv": 0.21428571428571427, "high_school_world_history_test.csv": 0.20512820512820512, "sociology_test.csv": 0.30303030303030304, "high_school_mathematics_test.csv": 0.1590909090909091, "high_school_macroeconomics_test.csv": 0.234375, "college_computer_science_test.csv": 0.3125, "medical_genetics_test.csv": 0.125, "high_school_physics_test.csv": 0.04, "security_studies_test.csv": 0.2, "electrical_engineering_test.csv": 0.08333333333333333, "high_school_chemistry_test.csv": 0.15151515151515152, "high_school_computer_science_test.csv": 0.1875, "nutrition_test.csv": 0.14, "moral_disputes_test.csv": 0.21052631578947367, "philosophy_test.csv": 0.3137254901960784, "college_medicine_test.csv": 0.21428571428571427, "computer_security_test.csv": 0.25, "jurisprudence_test.csv": 0.29411764705882354, "professional_law_test.csv": 0.21176470588235294, "high_school_government_and_politics_test.csv": 0.28125, "college_physics_test.csv": 0.375, "management_test.csv": 0.35294117647058826, "miscellaneous_test.csv": 0.24615384615384617, "human_aging_test.csv": 0.21621621621621623, "marketing_test.csv": 0.18421052631578946, "high_school_biology_test.csv": 0.19607843137254902, "human_sexuality_test.csv": 0.3333333333333333, "business_ethics_test.csv": 0.25, "high_school_geography_test.csv": 0.15625, "public_relations_test.csv": 0.2222222222222222, "logical_fallacies_test.csv": 0.18518518518518517, "high_school_microeconomics_test.csv": 0.28205128205128205, "high_school_psychology_test.csv": 0.2222222222222222, "us_foreign_policy_test.csv": 0.25, "elementary_mathematics_test.csv": 0.24193548387096775, "professional_psychology_test.csv": 0.1782178217821782, "formal_logic_test.csv": 0.05, "clinical_knowledge_test.csv": 0.20454545454545456, "conceptual_physics_test.csv": 0.1794871794871795, "econometrics_test.csv": 0.3333333333333333, "high_school_european_history_test.csv": 0.14814814814814814, "moral_scenarios_test.csv": 0.24161073825503357, "virology_test.csv": 0.25925925925925924, "international_law_test.csv": 0.15, "high_school_us_history_test.csv": 0.12121212121212122, "machine_learning_test.csv": 0.2222222222222222, "professional_medicine_test.csv": 0.2222222222222222, "college_chemistry_test.csv": 0.125, "prehistory_test.csv": 0.18867924528301888, "college_mathematics_test.csv": 0.3125, "global_facts_test.csv": 0.25, "abstract_algebra_test.csv": 0.1875, "college_biology_test.csv": 0.30434782608695654, "professional_accounting_test.csv": 0.30434782608695654}